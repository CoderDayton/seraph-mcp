# ==============================================================================
# 🌟 SERAPH MCP - Environment Configuration
# ==============================================================================
#
# ✨ WORKS WITH ZERO CONFIGURATION! ✨
#
# Seraph MCP uses intelligent auto-detection:
# - No config? Uses memory cache + deterministic Seraph compression (no AI needed)
# - Add provider? Auto-enables hybrid AI compression + budget tracking
# - Add Redis URL? Auto-switches to persistent Redis cache
# - Features light up automatically based on what you configure!
#
# ==============================================================================
# 📋 QUICKEST START (0 minutes): Just run it!
#   fastmcp dev src/server.py
#
# 🎯 Result: Works immediately with:
#   ✅ Memory cache (fast, no setup)
#   ✅ Seraph compression (deterministic, no AI needed)
#   ✅ All tools available (just no AI-powered features)
#
# ==============================================================================
# 🚀 FEATURE-RICH START (2 minutes): Add ONE provider
#   1. Copy this file: cp .env.example .env
#   2. Uncomment ONE provider section below (add API key + model)
#   3. Save and run: fastmcp dev src/server.py
#
# 🎯 Result: Auto-enables:
#   ✅ That provider
#   ✅ Hybrid AI + Seraph compression (best of both)
#   ✅ Budget tracking (cost monitoring)
#   ✅ Memory cache (still works)
#
# ==============================================================================
# 💎 PRODUCTION START (5 minutes): Add provider + Redis
#   1. Configure ONE provider below
#   2. Uncomment REDIS_URL
#   3. Optionally set budget limits
#
# 🎯 Result: Auto-enables:
#   ✅ Provider + hybrid compression
#   ✅ Redis persistent cache (survives restarts)
#   ✅ Budget tracking with alerts
#   ✅ Production-ready performance
#
# ==============================================================================

# ==============================================================================
# 🔑 OPTIONAL - AI Provider Configuration
# ==============================================================================
# Configure ONE or more providers to enable AI-powered features.
# Leave ALL commented to run with Seraph-only (no AI needed).
#
# 🎯 AUTO-ENABLING: Provider automatically enables when you set:
#    - API key + Model (+ Base URL for openai_compatible)
#
# 📊 What gets enabled:
#    ✅ That specific provider
#    ✅ Hybrid compression (AI + Seraph)
#    ✅ Budget tracking (cost monitoring)
#
# Get your API keys from:
# - OpenAI:    https://platform.openai.com/api-keys
# - Anthropic: https://console.anthropic.com/
# - Google AI: https://makersuite.google.com/app/apikey
# - Together:  https://api.together.xyz/settings/api-keys
# - Fireworks: https://fireworks.ai/api-keys
#
# ==============================================================================

# -----------------------------------------------------------------------------
# OpenAI (GPT-4, GPT-3.5-turbo, etc.)
# -----------------------------------------------------------------------------
# Uncomment both lines to enable OpenAI:
# OPENAI_API_KEY=sk-proj-...
# OPENAI_MODEL=gpt-4

# Optional: Override base URL (for proxies)
# OPENAI_BASE_URL=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# Anthropic (Claude models)
# -----------------------------------------------------------------------------
# Uncomment both lines to enable Anthropic:
# ANTHROPIC_API_KEY=sk-ant-...
# ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Optional: Override base URL
# ANTHROPIC_BASE_URL=https://api.anthropic.com

# -----------------------------------------------------------------------------
# Google AI (Gemini models)
# -----------------------------------------------------------------------------
# Uncomment both lines to enable Google AI:
# GEMINI_API_KEY=AIza...
# GEMINI_MODEL=gemini-1.5-pro

# Optional: Override base URL
# GEMINI_BASE_URL=https://generativelanguage.googleapis.com

# -----------------------------------------------------------------------------
# OpenAI-Compatible Providers (Together, Fireworks, Ollama, LM Studio, etc.)
# -----------------------------------------------------------------------------
# Uncomment all THREE lines to enable OpenAI-compatible provider:
#
# 🎯 MODEL + URL MATCHING: System matches your base_url + model to models.dev
#    Example: https://api.together.xyz/v1 + meta-llama/Llama-3-8b-chat-hf
#    → Looks up "together.ai" provider with "Llama-3-8b" in models.dev
#    → Gets accurate pricing and context limits
#
# OPENAI_COMPATIBLE_API_KEY=your-api-key-here
# OPENAI_COMPATIBLE_MODEL=meta-llama/Llama-3-8b-chat-hf
# OPENAI_COMPATIBLE_BASE_URL=https://api.together.xyz/v1

# Example: Together AI
# OPENAI_COMPATIBLE_API_KEY=your-together-key
# OPENAI_COMPATIBLE_MODEL=meta-llama/Llama-3-70b-chat-hf
# OPENAI_COMPATIBLE_BASE_URL=https://api.together.xyz/v1

# Example: Fireworks AI
# OPENAI_COMPATIBLE_API_KEY=your-fireworks-key
# OPENAI_COMPATIBLE_MODEL=accounts/fireworks/models/llama-v3-70b-instruct
# OPENAI_COMPATIBLE_BASE_URL=https://api.fireworks.ai/inference/v1

# Example: Local LM Studio
# OPENAI_COMPATIBLE_API_KEY=not-needed
# OPENAI_COMPATIBLE_MODEL=llama-3-8b
# OPENAI_COMPATIBLE_BASE_URL=http://localhost:1234/v1

# Example: Ollama
# OPENAI_COMPATIBLE_API_KEY=not-needed
# OPENAI_COMPATIBLE_MODEL=llama3:8b
# OPENAI_COMPATIBLE_BASE_URL=http://localhost:11434/v1

# ==============================================================================
# 💰 OPTIONAL - Budget Management
# ==============================================================================
# Set spending limits to prevent unexpected charges.
# Only works if at least one provider is configured (since providers = costs).
#
# 🎯 AUTO-ENABLING: Budget tracking automatically starts when:
#    - Any provider is configured (has costs to track)
#
# Leave commented for unlimited spending (not recommended for production).
#
# 💡 TIP: Start conservative, adjust based on actual usage.
# ==============================================================================

# Daily spending cap (USD)
# Example: 10.0 = $10/day maximum
# DAILY_BUDGET_LIMIT=10.0

# Monthly spending cap (USD)
# Example: 200.0 = $200/month maximum
# MONTHLY_BUDGET_LIMIT=200.0

# Budget alert thresholds (percentage of limit)
# Default: Get notified at 50%, 75%, and 90% of budget
# BUDGET_ALERT_THRESHOLDS=50.0,75.0,90.0

# ==============================================================================
# 💾 OPTIONAL - Redis Cache (Persistent Storage)
# ==============================================================================
# Seraph uses memory cache by default (fast, no setup, works great).
# Add Redis URL for persistence across restarts and shared cache.
#
# 🎯 AUTO-ENABLING: Redis cache automatically enables when:
#    - REDIS_URL is set (system detects Redis and switches to it)
#
# Leave commented to use memory cache (recommended for development).
# ==============================================================================

# Redis URL for persistent cache
# Uncomment to auto-enable Redis cache:
# REDIS_URL=redis://localhost:6379

# Redis connection pool size (optional, good defaults)
# REDIS_MAX_CONNECTIONS=10

# Redis socket timeout in seconds (optional)
# REDIS_SOCKET_TIMEOUT=5

# ==============================================================================
# 🎯 OPTIONAL - Context Optimization (Hybrid Compression)
# ==============================================================================
# NEW: Hybrid compression system combining AI and deterministic compression.
#
# 🎯 AUTO-BEHAVIOR:
#    - No provider: Uses Seraph-only (deterministic, no AI needed)
#    - Provider configured: Uses hybrid (AI + Seraph for best results)
#    - All settings below are OPTIONAL with smart defaults
#
# Three compression methods:
# - "auto": Smart selection (Seraph-only if no provider, else hybrid based on size)
# - "ai": Always AI (requires provider, fast, nuanced)
# - "seraph": Always deterministic (works without provider, cacheable)
# - "hybrid": AI + Seraph (requires provider, best compression + quality)
#
# 💡 TIP: Leave everything default - it works great automatically!
# ==============================================================================

# Enable/disable context optimization (default: true)
# Set to false to disable ALL compression
# CONTEXT_OPTIMIZATION_ENABLED=true

# Compression method (default: auto - smart selection)
# Options: auto, ai, seraph, hybrid
# - auto: Seraph if no provider; else AI for ≤3k tokens, Seraph for >3k
# - seraph: Always deterministic (works without provider)
# - ai: Always AI-powered (requires provider)
# - hybrid: Seraph + AI polish (requires provider)
# CONTEXT_OPTIMIZATION_COMPRESSION_METHOD=auto

# Token threshold for auto mode (default: 3000)
# When method=auto with provider: ≤3k uses AI, >3k uses Seraph
# CONTEXT_OPTIMIZATION_SERAPH_TOKEN_THRESHOLD=3000

# Quality threshold 0.0-1.0 (default: 0.90 = 90% quality preservation)
# Lower = more aggressive compression, higher = more conservative
# CONTEXT_OPTIMIZATION_QUALITY_THRESHOLD=0.90

# Maximum processing overhead in milliseconds (default: 100.0)
# Optimization timeout - reverts to original if exceeded
# CONTEXT_OPTIMIZATION_MAX_OVERHEAD_MS=100.0

# ==============================================================================
# 🔧 ADVANCED - Seraph Compression Layer Tuning
# ==============================================================================
# Fine-tune the deterministic multi-layer compression ratios.
# ONLY adjust if you understand the tradeoffs!
#
# L1: Ultra-small skeleton (0.2% of original - bullets from entities/quantities)
# L2: Compact abstracts (1% of original - section summaries)
# L3: Factual extracts (5% of original - top salient chunks via BM25)
# ==============================================================================

# L1 layer ratio (default: 0.002 = 0.2% of original)
# CONTEXT_OPTIMIZATION_SERAPH_L1_RATIO=0.002

# L2 layer ratio (default: 0.01 = 1% of original)
# CONTEXT_OPTIMIZATION_SERAPH_L2_RATIO=0.01

# L3 layer ratio (default: 0.05 = 5% of original)
# CONTEXT_OPTIMIZATION_SERAPH_L3_RATIO=0.05

# ==============================================================================
# 🎛️ OPTIONAL - Core Settings
# ==============================================================================
# General system configuration with excellent defaults.
# ==============================================================================

# Environment (development, staging, production)
# ENVIRONMENT=development

# Logging level (DEBUG, INFO, WARNING, ERROR)
# Default: INFO - use DEBUG for troubleshooting
# LOG_LEVEL=INFO

# Cache time-to-live in seconds (default: 3600 = 1 hour)
# CACHE_TTL_SECONDS=3600

# Maximum cache entries for memory cache (default: 1000)
# CACHE_MAX_SIZE=1000

# Cache namespace for multiple apps sharing Redis (default: seraph)
# CACHE_NAMESPACE=seraph

# ==============================================================================
# 🔌 ADVANCED - Provider Timeouts & Retries
# ==============================================================================
# Fine-tune provider behavior. Defaults are production-tested.
# ==============================================================================

# OpenAI timeouts and retries
# OPENAI_TIMEOUT=30.0
# OPENAI_MAX_RETRIES=3

# Anthropic timeouts and retries
# ANTHROPIC_TIMEOUT=30.0
# ANTHROPIC_MAX_RETRIES=3

# Gemini timeouts and retries
# GEMINI_TIMEOUT=30.0
# GEMINI_MAX_RETRIES=3

# OpenAI-Compatible timeouts and retries
# OPENAI_COMPATIBLE_TIMEOUT=30.0
# OPENAI_COMPATIBLE_MAX_RETRIES=3

# ==============================================================================
# 📊 ADVANCED - Observability
# ==============================================================================
# Enable metrics, tracing, and monitoring integrations.
# ==============================================================================

# Observability backend (simple, prometheus, datadog)
# OBSERVABILITY_BACKEND=simple

# Enable Prometheus metrics endpoint
# ENABLE_METRICS=true
# METRICS_PORT=9090
# PROMETHEUS_PATH=/metrics

# Enable distributed tracing
# ENABLE_TRACING=false

# Datadog integration (if using datadog backend)
# DATADOG_API_KEY=your-datadog-api-key
# DATADOG_SITE=datadoghq.com

# ==============================================================================
# 🔐 ADVANCED - Security (Production Only)
# ==============================================================================
# Additional security controls for production deployments.
# ==============================================================================

# Enable API key authentication
# ENABLE_AUTH=false

# Comma-separated list of valid API keys
# API_KEYS=key1,key2,key3

# Require HTTPS for all requests
# REQUIRE_HTTPS=false

# Allowed hosts (comma-separated, * for all)
# ALLOWED_HOSTS=*

# ==============================================================================
# ✅ CONFIGURATION EXAMPLES
# ==============================================================================
#
# 📦 Example 1: MINIMAL (Zero Config - Just Works!)
#   (Leave everything commented)
#   Result: Memory cache + Seraph compression (no AI needed)
#
# 🚀 Example 2: BASIC AI FEATURES (Most Common)
#   OPENAI_API_KEY=sk-proj-...
#   OPENAI_MODEL=gpt-4
#   MONTHLY_BUDGET_LIMIT=200.0
#   Result: OpenAI + hybrid compression + budget tracking + memory cache
#
# 💎 Example 3: PRODUCTION (Full Featured)
#   OPENAI_API_KEY=sk-proj-...
#   OPENAI_MODEL=gpt-4
#   REDIS_URL=redis://localhost:6379
#   DAILY_BUDGET_LIMIT=10.0
#   MONTHLY_BUDGET_LIMIT=200.0
#   LOG_LEVEL=INFO
#   Result: OpenAI + Redis cache + budget limits + hybrid compression
#
# 🔧 Example 4: LOCAL TESTING (No Cost)
#   OPENAI_COMPATIBLE_API_KEY=not-needed
#   OPENAI_COMPATIBLE_MODEL=llama-3-8b
#   OPENAI_COMPATIBLE_BASE_URL=http://localhost:1234/v1
#   Result: Local LLM + hybrid compression + no costs
#
# 🎯 Example 5: SERAPH-ONLY (No AI at all)
#   (Leave all providers commented)
#   CONTEXT_OPTIMIZATION_COMPRESSION_METHOD=seraph
#   Result: Pure deterministic compression, zero AI costs
#
# ==============================================================================
# 📚 NEXT STEPS
# ==============================================================================
#
# 1. Choose your configuration level above (Minimal/Basic/Production/etc)
# 2. Save this file as .env
# 3. Uncomment only what you need (everything else works automatically!)
# 4. Run: fastmcp dev src/server.py
# 5. Features will auto-enable based on your configuration
#
# 🎯 Remember: The system is designed to work with ZERO configuration!
#              Add features progressively as you need them.
#
# ==============================================================================
# 🆘 SUPPORT
# ==============================================================================
#
# 📖 Documentation:
#   - Full docs: docs/SDD.md
#   - Context optimization: src/context_optimization/README.md
#   - Troubleshooting: README.md
#
# 💬 Community:
#   - GitHub Issues: https://github.com/yourusername/seraph-mcp/issues
#   - GitHub Discussions: https://github.com/yourusername/seraph-mcp/discussions
#
# ==============================================================================
